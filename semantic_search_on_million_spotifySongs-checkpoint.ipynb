{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e681c0-12c2-4f1f-9336-a124cc049230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used dataset : https://www.kaggle.com/datasets/joebeachcapital/30000-spotify-songs/data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import ast\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(torch.cuda.is_available())  # True\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # free, fast, 384-dim\n",
    "\n",
    "df = pd.read_csv(\"./dataset/millionSongs.csv\")\n",
    "\n",
    "df[\"artists\"] = df[\"artists\"].apply(ast.literal_eval)\n",
    "\n",
    "def build_semantic_text(row):\n",
    "    artists = \", \".join(row[\"artists\"])\n",
    "    return (\n",
    "        f\"Song: {row['name']} by {artists}. \"\n",
    "        f\"Album: {row['album']}. Released in {row['year']} on {row['release_date']}. \"\n",
    "        f\"This track is characterized by danceability {row['danceability']}, energy {row['energy']}, \"\n",
    "        f\"valence {row['valence']}, acousticness {row['acousticness']}, instrumentalness {row['instrumentalness']}, \"\n",
    "        f\"speechiness {row['speechiness']}, liveness {row['liveness']}, loudness {row['loudness']}, \"\n",
    "        f\"and tempo {row['tempo']} BPM. \"\n",
    "        f\"It has a key of {row['key']}, mode {row['mode']}, and a time signature of {row['time_signature']}. \"\n",
    "        f\"Duration: {row['duration_ms']} milliseconds.\"\n",
    "    )\n",
    "\n",
    "df[\"semantic_text\"] = df.apply(build_semantic_text, axis=1)\n",
    "\n",
    "texts = df[\"semantic_text\"].tolist()\n",
    "\n",
    "embeddings = model.encode(texts, batch_size=128, device=\"cuda\", show_progress_bar=True)\n",
    "\n",
    "# df[\"embedding\"] = df[\"semantic_text\"].apply(lambda x: model.encode(x).tolist())\n",
    "\n",
    "df[\"embedding\"] = embeddings.tolist()\n",
    "\n",
    "with open(\"./million_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c8e2d-35cd-4bba-8feb-8f007bb7238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(torch.cuda.is_available())  # True\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # free, fast, 384-dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a57838d0-0ef1-4acb-82cc-4b38ac90a339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1204025, 384)\n"
     ]
    }
   ],
   "source": [
    "embeddings = df[\"embedding\"]\n",
    "\n",
    "#embeddings_np = np.array(embeddings)  # shape: (num_songs, 384) this is giving 1D arrray\n",
    "embeddings_np = np.stack(df[\"embedding\"].values).astype(\"float32\")  # shape: (num_songs, 384)\n",
    "print(embeddings_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cef6457-0cbd-482f-a543-f300b9df6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "faiss.normalize_L2(embeddings_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c969988-117f-4c15-93cb-6b19f03e7340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in index: 1204025\n",
      "Song: Rap Battle : 0.6036165356636047\n",
      "Song: Victory (feat. The Notorious B.I.G. & Busta Rhymes) : 0.5630593299865723\n",
      "Song: Rappers Battle : 0.5559302568435669\n",
      "Song: BRING IT ON 〜Battle of Rap〜 : 0.5446075201034546\n",
      "Song: George Washington vs William Wallace : 0.544097363948822\n",
      "Song: The Battle : 0.5433796048164368\n",
      "Song: Victory (feat. The Notorious B.I.G. & Busta Rhymes) - 2014 Remaster : 0.5424882173538208\n",
      "Song: When Rappers Attack : 0.5419893264770508\n",
      "Song: Battle Rhymes For Battle Times : 0.5373817682266235\n",
      "Song: Rap Supremacy (Remix) : 0.5367496609687805\n"
     ]
    }
   ],
   "source": [
    "d = embeddings_np.shape[1]  # embedding dimension (384)\n",
    "index = faiss.IndexFlatIP(d)  # inner product index\n",
    "index.add(embeddings_np)      # add all embeddings to index\n",
    "\n",
    "print(\"Number of vectors in index:\", index.ntotal)\n",
    "q = \"rap battle\"\n",
    "q_emb = model.encode(q).astype(\"float32\").reshape(1, -1)\n",
    "\n",
    "faiss.normalize_L2(q_emb)\n",
    "\n",
    "score, index = index.search(q_emb, 10)\n",
    "\n",
    "for idx, scr in zip(index[0], score[0]):\n",
    "    print(f\"Song: {df['name'].iloc[idx]} : {scr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f668f-0e36-47c1-b063-d5f2c61c3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works but is slow af for data with millions of items\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def cosine_similarity_np(A, B):\n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "    return np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
    "\n",
    "q = \"pop\"\n",
    "q_emb = model.encode(q)\n",
    "q_emb = q_emb.reshape(1, -1)          # shape: (1, 384)\n",
    "\n",
    "similarities = (embeddings_np @ q_emb.T).flatten()  # dot product\n",
    "similarities /= np.linalg.norm(embeddings_np, axis=1)\n",
    "similarities /= np.linalg.norm(q_emb)\n",
    "\n",
    "top_idx = np.argsort(-similarities)[:10]\n",
    "\n",
    "for i in top_idx:\n",
    "    print(f\"{df['name'][i]}: {similarities[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb60113-1c95-4438-96c1-e3f09d4c8655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Slowest approch below ---\n",
    "    \n",
    "# similarities = [cosine_similarity_np(q_emb, song_emb) for song_emb in embeddings]\n",
    "    \n",
    "# songs = df[\"name\"]\n",
    "\n",
    "# results = list(zip(songs, similarities))\n",
    "\n",
    "# # Sort by similarity descending\n",
    "# results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # Top 10 similar songs\n",
    "# top_10 = results[:10]\n",
    "\n",
    "# for song, score in top_10:\n",
    "#     print(f\"{song}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29615cd-7751-448d-a858-f7fb1f58b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del df\n",
    "del texts\n",
    "del embeddings\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3191e247-2b10-4056-8f10-9ab932a86d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
